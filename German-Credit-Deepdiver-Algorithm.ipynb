{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ab2386",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9389daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from classifier import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from demo_parity_calc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4eb07cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['status', 'duration', 'credit_hist', 'purpose', 'credit_amt', 'savings', 'employment', 'installment_rate', 'personal_status', 'debtors', 'residencesince', 'property', 'age', 'install_plans', 'housing', 'existing_credits', 'job', 'maintenance_paying_people', 'telephone', 'foreign_worker', 'result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a17f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('german.data', names=cols, sep=\" \", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e5c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_german(df): \n",
    "    df['status'] = df['status'].map({'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}).astype(int)\n",
    "    df['credit_hist'] = df['credit_hist'].map({'A34': 0, 'A33': 1, 'A32': 2, 'A31': 3, 'A30': 4}).astype(int)\n",
    "    df.loc[(df['credit_amt'] <= 2000), 'credit_amt'] = 0\n",
    "    df.loc[(df['credit_amt'] > 2000) & (df['credit_amt'] <= 5000), 'credit_amt'] = 1\n",
    "    df.loc[(df['credit_amt'] > 5000), 'credit_amt'] = 2   \n",
    "    df.loc[(df['duration'] <= 12), 'duration'] = 0\n",
    "    df.loc[(df['duration'] > 12) & (df['duration'] <= 24), 'duration'] = 1\n",
    "    df.loc[(df['duration'] > 24) & (df['duration'] <= 36), 'duration'] = 2\n",
    "    df.loc[(df['duration'] > 36), 'duration'] = 3\n",
    "    df['age'] = df['age'].apply(lambda x : 1 if x >= 45 else 0) # 1 if old, 0 if young\n",
    "    df['savings'] = df['savings'].map({'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}).astype(int)\n",
    "    df['employment'] = df['employment'].map({'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}).astype(int)    \n",
    "    df['gender'] = df['personal_status'].map({'A91': 1, 'A92': 0, 'A93': 1, 'A94': 1, 'A95': 0}).astype(int)\n",
    "    df['debtors'] = df['debtors'].map({'A101': 0, 'A102': 1, 'A103': 2}).astype(int)\n",
    "    df['property'] = df['property'].map({'A121': 3, 'A122': 2, 'A123': 1, 'A124': 0}).astype(int)        \n",
    "    df['install_plans'] = df['install_plans'].map({'A141': 1, 'A142': 1, 'A143': 0}).astype(int)\n",
    "    df['job'] = df['job'].map({'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}).astype(int)    \n",
    "    df['telephone'] = df['telephone'].map({'A191': 0, 'A192': 1}).astype(int)\n",
    "    df['foreign_worker'] = df['foreign_worker'].map({'A201': 1, 'A202': 0}).astype(int)\n",
    "    pd.get_dummies(df, columns=['purpose', 'housing'], drop_first=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110be361",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_german(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdd558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"purpose\", \"housing\", \"personal_status\", \"result\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d284836f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_hist</th>\n",
       "      <th>credit_amt</th>\n",
       "      <th>savings</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>debtors</th>\n",
       "      <th>residencesince</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>install_plans</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>maintenance_paying_people</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   status  duration  credit_hist  credit_amt  savings  employment  \\\n",
       "0       0         0            0           0        4           4   \n",
       "1       1         3            2           2        0           2   \n",
       "2       3         0            0           1        0           3   \n",
       "3       0         3            2           2        0           3   \n",
       "4       0         1            1           1        0           2   \n",
       "\n",
       "   installment_rate  debtors  residencesince  property  age  install_plans  \\\n",
       "0                 4        0               4         3    1              0   \n",
       "1                 2        0               2         3    0              0   \n",
       "2                 2        0               3         3    1              0   \n",
       "3                 2        2               4         2    1              0   \n",
       "4                 3        0               4         0    1              0   \n",
       "\n",
       "   existing_credits  job  maintenance_paying_people  telephone  \\\n",
       "0                 2    2                          1          1   \n",
       "1                 1    2                          1          0   \n",
       "2                 1    1                          2          0   \n",
       "3                 1    2                          2          0   \n",
       "4                 2    2                          2          0   \n",
       "\n",
       "   foreign_worker  gender  \n",
       "0               1       1  \n",
       "1               1       0  \n",
       "2               1       1  \n",
       "3               1       1  \n",
       "4               1       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85ce9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_pattern(string1, string2):\n",
    "    if len(string1) == len(string2):\n",
    "        for i in range(len(string1)):\n",
    "            if string1[i].isdigit() and string2[i].isdigit():\n",
    "                if string1[i] != string2[i]:\n",
    "                    return 0\n",
    "        else:\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4c1253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patterns(df, threshold):\n",
    "    patterns = ['XXXXXXXXXXXXXXXXXX', \n",
    "                'XXXXXXXXXXXXXXXXX0',\n",
    "                'XXXXXXXXXXXXXXXX00',\n",
    "                'XXXXXXXXXXXXXXXX10', \n",
    "                'XXXXXXXXXXXXXXXXX1', \n",
    "                'XXXXXXXXXXXXXXXX01', \n",
    "                'XXXXXXXXXXXXXXXX11' ]\n",
    "    # Initialize a dictionary to store the pattern counts\n",
    "    pattern_counts = {pattern: 0 for pattern in patterns}\n",
    "\n",
    "    # Iterate through each row of the dataset\n",
    "    for i in range(len(df)):\n",
    "        # Iterate through each pattern\n",
    "        for pattern in patterns:\n",
    "            res = match_pattern(pattern, \"\".join(str(x) for x in df.iloc[i].values.tolist()))\n",
    "            # Increment the count for the pattern if it is found\n",
    "            if res == 1:\n",
    "                pattern_counts[pattern] += 1\n",
    "\n",
    "    # Output the pattern counts\n",
    "    print('Pattern counts:')\n",
    "    for pattern, count in pattern_counts.items():\n",
    "        print(pattern + \": \" + str(count))\n",
    "        \n",
    "    print('\\nUncovered patterns:')\n",
    "    for pattern, count in pattern_counts.items():\n",
    "        if count < threshold:\n",
    "            print(pattern)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9554015f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern counts:\n",
      "XXXXXXXXXXXXXXXXXX: 1000\n",
      "XXXXXXXXXXXXXXXXX0: 310\n",
      "XXXXXXXXXXXXXXXX00: 7\n",
      "XXXXXXXXXXXXXXXX10: 303\n",
      "XXXXXXXXXXXXXXXXX1: 690\n",
      "XXXXXXXXXXXXXXXX01: 30\n",
      "XXXXXXXXXXXXXXXX11: 660\n",
      "\n",
      "Uncovered patterns:\n",
      "XXXXXXXXXXXXXXXX00\n",
      "XXXXXXXXXXXXXXXX01\n"
     ]
    }
   ],
   "source": [
    "create_patterns(df, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f783d690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000044404310221111'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(str(x) for x in df.iloc[0].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad5cd4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "res = match_pattern('xxxx0', '11110')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be773274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "duration\n",
      "credit_hist\n",
      "credit_amt\n",
      "savings\n",
      "employment\n",
      "installment_rate\n",
      "debtors\n",
      "residencesince\n",
      "property\n",
      "age\n",
      "install_plans\n",
      "existing_credits\n",
      "job\n",
      "maintenance_paying_people\n",
      "telephone\n",
      "foreign_worker\n",
      "gender\n"
     ]
    }
   ],
   "source": [
    "for item in df: \n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98d8e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Return the inverted index matrix for the dataset\n",
    "def preprocessing(dataset):\n",
    "    \n",
    "    #Get cardinalities out of the dataset\n",
    "    cardinalities = []\n",
    "#     cardinalities = [[0,1],[0,1],[0,1]]\n",
    "    for col in dataset.columns:\n",
    "        cardinalities.append(dataset[col].unique().tolist())\n",
    "\n",
    "    for cardinality in cardinalities:\n",
    "        cardinality.sort()\n",
    "        \n",
    "    num = 1\n",
    "    for cardinality in cardinalities:\n",
    "        num *= len(cardinality)+1\n",
    "        \n",
    "    print('Total number of patterns in the dataset: ',num)\n",
    "\n",
    "\n",
    "    #Get unique value combinations count\n",
    "    dataset_string = []\n",
    "#     dataset_string = ['010','001','000','011','001']\n",
    "    for i in range(len(dataset)):\n",
    "        dataset_string.append(\"\".join(str(x) for x in dataset.iloc[i].values.tolist()))\n",
    "        \n",
    "    counts = OrderedDict()\n",
    "\n",
    "    for item in dataset_string:\n",
    "        counts[item] = counts.get(item, 0) + 1\n",
    "\n",
    "    data_unique_values = list(counts.keys())\n",
    "    data_value_counts = list(counts.values())\n",
    "    \n",
    "    inverted_ind = []\n",
    "    \n",
    "    #create inverted index matrix\n",
    "    for i,cardinality in enumerate(cardinalities):\n",
    "        for cardinality_val in cardinality:\n",
    "            new_row = []\n",
    "            for val in data_unique_values:\n",
    "                if cardinality_val == int(val[i]):\n",
    "                    new_row.append(1)\n",
    "                else:\n",
    "                    new_row.append(0) \n",
    "            inverted_ind.append(new_row)\n",
    "            \n",
    "    return inverted_ind, data_value_counts, cardinalities\n",
    "        \n",
    "\n",
    "def cov(pattern, dataset):  #tested_OK\n",
    "    \"\"\"\n",
    "    Returns the number of instances in the dataset covered by the given pattern.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        res = match_pattern(pattern, \"\".join(str(x) for x in df.iloc[i].values.tolist()))\n",
    "        if res == 1:\n",
    "            count += 1\n",
    "#     print(count)\n",
    "    return count\n",
    "\n",
    "\n",
    "def coverage_optimized(pattern, inverted_ind, data_value_counts, cardinalities):  #invertedindices  #tested_OK for the example given in the research paper\n",
    "\n",
    "    result_and = [1] * len(inverted_ind[0])\n",
    "    row_index = 0\n",
    "    for i,x in enumerate(pattern):\n",
    "        if x!= 'X':\n",
    "            \n",
    "            #find the value x in cardinalities[i]\n",
    "            index = cardinalities[i].index(int(x))\n",
    "            row_index += index\n",
    "            inverted_ind_row = inverted_ind[row_index]\n",
    "            for j in range(len(inverted_ind_row)):\n",
    "                result_and[j] = int(inverted_ind_row[j] and result_and[j])\n",
    "            row_index -= index\n",
    "            row_index += len(cardinalities[i])\n",
    "        else:\n",
    "            row_index += len(cardinalities[i])      \n",
    "\n",
    "    # DOT Product between the above result and the count array for the datapoints\n",
    "    coverage = sum([x*y for x, y in zip(data_value_counts, result_and)])\n",
    "    return coverage\n",
    "    \n",
    "\n",
    "def generate_parent_nodes(pattern):  #tested_OK\n",
    "    \"\"\"\n",
    "    Generates all parent nodes of the given pattern by replacing one deterministic\n",
    "    cell with a wildcard character.\n",
    "    \"\"\"\n",
    "    parents = []\n",
    "    for i in range(len(pattern)):\n",
    "        new_string = pattern[:i] + \"X\" + pattern[i+1:]\n",
    "        if new_string != pattern:\n",
    "            parents.append(new_string)\n",
    "    return parents\n",
    "\n",
    "\n",
    "def generate_nodes(pattern, cardinalities): #tested_OK\n",
    "    \"\"\"\n",
    "    Generates all nodes on the given pattern and cardinalities based on Rule 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: Make cardinalities 2D vector, so that it can be traversed to find the children of a pattern\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the index of the right-most deterministic element in the pattern\n",
    "    index = len(pattern) - 1\n",
    "    rm_deter = -1\n",
    "    while index >= 0:\n",
    "        if pattern[index] != 'X':\n",
    "            rm_deter = index\n",
    "            break\n",
    "        index -= 1\n",
    "\n",
    "    candidate_nodes = []\n",
    "    rm_deter += 1\n",
    "    if rm_deter >= 0:\n",
    "        while rm_deter < len(pattern):\n",
    "            index = rm_deter\n",
    "            for value in cardinalities[index]:\n",
    "                candidate_node = pattern\n",
    "                candidate_node = pattern[:index] + str(value) + pattern[index+1:] \n",
    "                candidate_nodes.append(candidate_node)\n",
    "            rm_deter += 1\n",
    "\n",
    "    return candidate_nodes\n",
    "\n",
    "\n",
    "def dominance(pattern, mups):\n",
    "    #iterate through the mups, find if any of the mups is an ancestor for the pattern p return 0\n",
    "    # if pattern p is an ancestor for any of the mups return 1\n",
    "    # else return -1\n",
    "    \n",
    "    for m in mups:\n",
    "        for i,x in enumerate(m):\n",
    "            if m[i] != pattern[i]:\n",
    "                if m[i] == 'X' and pattern[i] != 'X':\n",
    "                    return 0\n",
    "                elif m[i] != 'X' and pattern[i] == 'X':\n",
    "                    return 1\n",
    "    \n",
    "    return -1\n",
    "\n",
    "    \n",
    "def deepdiver(dataset, threshold):\n",
    "    \"\"\"\n",
    "    Finds the maximal uncovered patterns in the dataset.\n",
    "    \"\"\" \n",
    "    inverted_index, unique_value_counts, cardinalities = preprocessing(dataset);\n",
    "\n",
    "    stack = ['XXXXXXXXXXXXXXXXXX']\n",
    "    maximal_uncovered = []\n",
    "    while stack:\n",
    "        pattern = stack.pop()\n",
    "        uncovered_flag = False\n",
    "        if dominance(pattern, maximal_uncovered) == 0:\n",
    "            continue\n",
    "        elif dominance(pattern, maximal_uncovered) == 1:\n",
    "            uncovered_flag = False\n",
    "        else: \n",
    "            count = coverage_optimized(pattern, inverted_index, unique_value_counts, cardinalities)\n",
    "            if count < threshold:\n",
    "                uncovered_flag = True\n",
    "        if uncovered_flag:\n",
    "            stack0 = []\n",
    "            stack0.append(pattern)\n",
    "            while stack0:\n",
    "                pattern0 = stack0.pop()\n",
    "                parent_nodes = generate_parent_nodes(pattern0)\n",
    "                for p in parent_nodes:\n",
    "                    count0 = coverage_optimized(p, inverted_index, unique_value_counts, cardinalities )\n",
    "                    if count0 < threshold:\n",
    "                        stack0.append(p)\n",
    "                        break                   \n",
    "                maximal_uncovered.append(pattern)\n",
    "        else:\n",
    "            stack.extend(generate_nodes(pattern, cardinalities))\n",
    "            \n",
    "    print('MUPs are: ', maximal_uncovered)\n",
    "    return maximal_uncovered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80b18452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     #MUPs\n",
    "#     print('MUP coverage')\n",
    "#     print(coverage_optimized('XXXXXXXXXXXXXXX101', inverted_index, unique_value_counts, cardinalities))\n",
    "#     print(coverage_optimized('XXXXXXXXXXXXXXX100', inverted_index, unique_value_counts, cardinalities))\n",
    "    \n",
    "#     #MUP Parents\n",
    "#     print('MUP Parents coverage')\n",
    "#     print(coverage_optimized('XXXXXXXXXXXXXXXX01', inverted_index, unique_value_counts, cardinalities))\n",
    "#     print(coverage_optimized('XXXXXXXXXXXXXXXX00', inverted_index, unique_value_counts, cardinalities))\n",
    "#     print(coverage_optimized('XXXXXXXXXXXXXXX1X1', inverted_index, unique_value_counts, cardinalities))\n",
    "#     print(coverage_optimized('XXXXXXXXXXXXXXX1X0', inverted_index, unique_value_counts, cardinalities))\n",
    "    \n",
    "#     #MUP Children\n",
    "#     print('MUP children coverage')\n",
    "#     print(coverage_optimized('X0XXXXXXXXXXXXX101', inverted_index, unique_value_counts, cardinalities))\n",
    "#     print(coverage_optimized('X01XXXXXXXXXXXX100', inverted_index, unique_value_counts, cardinalities))\n",
    "#     print(coverage_optimized('3XXXXXXXXXXXXXX101', inverted_index, unique_value_counts, cardinalities))\n",
    "#     print(coverage_optimized('2XXXXXXXXXXXXXX100', inverted_index, unique_value_counts, cardinalities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2751162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inv, d, cardinalities = preprocessing(df)\n",
    "# print(coverage_optimized('3XXXXXXXXXXX1XXX11',inv,d,cardinalities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c33f3f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = [[0,1,0],[0,0,1],[0,0,0],[0,1,1],[0,0,1]]\n",
    "# deepdiver(df1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e2217f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patterns in the dataset:  196830000000\n",
      "MUPs are:  ['XXXXXXXXXXXXXXXX00']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XXXXXXXXXXXXXXXX00']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepdiver(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3738d2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patterns in the dataset:  196830000000\n",
      "MUPs are:  ['XXXXXXXXXXXXXXXXX0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XXXXXXXXXXXXXXXXX0']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepdiver(df, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b77192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patterns in the dataset:  196830000000\n",
      "MUPs are:  ['XXXXXXXXXXXXXXXX0X']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XXXXXXXXXXXXXXXX0X']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepdiver(df, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81e2b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStringsMatchingWithPattern(pattern, df):\n",
    "    \n",
    "    \n",
    "    #Get unique value combinations count\n",
    "    dataset_string = []\n",
    "    for i in range(len(df)):\n",
    "        dataset_string.append(\"\".join(str(x) for x in df.iloc[i].values.tolist()))\n",
    "        \n",
    "    \n",
    "    strings = []\n",
    "    flag = True\n",
    "    for s in dataset_string:\n",
    "        flag = True\n",
    "        for i,x in enumerate(s):\n",
    "            if x != pattern[i]:\n",
    "                if pattern[i] != 'X':\n",
    "#                     print('string:',s[i])\n",
    "#                     print('string:',pattern[i])\n",
    "                    flag = False\n",
    "                    \n",
    "        if flag:\n",
    "            strings.append(s)\n",
    "            \n",
    "    print(len(strings))       \n",
    "    return strings\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "931a4ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['012241102200121100', '000141213300221000', '102002102100121000', '000003403200221000', '013102124101121000', '300033302200121000', '134202102201131100']\n"
     ]
    }
   ],
   "source": [
    "print(getStringsMatchingWithPattern('XXXXXXXXXXXXXXXX00', df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edd988d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "['000101103310212001', '300142201100221001', '012241102200121100', '000141213300221000', '202031202300101001', '302002104200121101', '000014324310222001', '102002422300121001', '302033302210121001', '304012401001121001', '300004304300212001', '012204104210131101', '312143403200121001', '302002202300121101', '302044412210111001', '202041102300112001', '000103104300211001', '102002102100121000', '012001402300121001', '302022302000112001', '302012302300111001', '000102302300212001', '000003403200221000', '000001204300112001', '013102124101121000', '102003423300221001', '200002101310302001', '102001303300111001', '010102422201221001', '302112122300122001', '200004104310222001', '000102404201211001', '300033302200121000', '012143212300111001', '134202102201131100', '012001411200111001', '302002302300112001']\n"
     ]
    }
   ],
   "source": [
    "print(getStringsMatchingWithPattern( 'XXXXXXXXXXXXXXXX0X', df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b0c4caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_da = pd.read_table('german.data', names=cols, sep=\" \", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e26ab807",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_da = preprocess_german(df_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86e95634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_da = df_da.drop([\"purpose\", \"housing\", \"personal_status\"], axis=1)\n",
    "x = df_da[['status', 'duration', 'credit_hist', 'credit_amt', 'savings',\n",
    "       'employment', 'installment_rate', 'debtors', 'residencesince',\n",
    "       'property', 'age', 'install_plans', 'existing_credits', 'job',\n",
    "       'maintenance_paying_people', 'telephone', 'foreign_worker',\n",
    "       'gender']]\n",
    "\n",
    "y = df_da['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d3e1036",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1)\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test_scalar = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c1646c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name = 'LogisticRegression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6b1b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_parity(x_train_temp, y_train_temp, x_test_temp):\n",
    "    # find the predictive probabilities for the protected and privileged groups based on 'age'\n",
    "    sc = StandardScaler()\n",
    "    x_test_scalar_temp = sc.fit_transform(x_test_temp)\n",
    "\n",
    "    clf = eval(clf_name)\n",
    "    clf.fit(x_train_temp, y_train_temp)(input_size=x_train_temp.shape[-1])\n",
    "\n",
    "    y_pred_proba_temp = clf.predict_proba(x_test_scalar_temp)\n",
    "\n",
    "    privileged_gp_indices = x_test_temp[x_test_temp['age'] == 1].index\n",
    "    protected_gp_indices = x_test_temp[x_test_temp['age'] == 0].index\n",
    "\n",
    "    privileged_positive_pred = 0\n",
    "    for x in range(len(privileged_gp_indices)):\n",
    "        privileged_positive_pred += y_pred_proba_temp[privileged_gp_indices[x]]\n",
    "    privileged_positive_pred /= len(privileged_gp_indices)\n",
    "\n",
    "    protected_positive_pred = 0\n",
    "    for x in range(len(protected_gp_indices)):\n",
    "        protected_positive_pred += y_pred_proba_temp[protected_gp_indices[x]]\n",
    "    protected_positive_pred /= len(protected_gp_indices)\n",
    "\n",
    "    return  protected_positive_pred - privileged_positive_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1eb52a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      2\n",
      "      ..\n",
      "795    1\n",
      "796    1\n",
      "797    1\n",
      "798    2\n",
      "799    2\n",
      "Name: result, Length: 800, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c22669e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dp_ori \u001b[38;5;241m=\u001b[39m \u001b[43mdemographic_parity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(dp_ori)\n",
      "Cell \u001b[1;32mIn[29], line 7\u001b[0m, in \u001b[0;36mdemographic_parity\u001b[1;34m(x_train_temp, y_train_temp, x_test_temp)\u001b[0m\n\u001b[0;32m      4\u001b[0m x_test_scalar_temp \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mfit_transform(x_test_temp)\n\u001b[0;32m      6\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(clf_name)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_temp\u001b[49m\u001b[43m)\u001b[49m(input_size\u001b[38;5;241m=\u001b[39mx_train_temp\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      9\u001b[0m y_pred_proba_temp \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(x_test_scalar_temp)\n\u001b[0;32m     11\u001b[0m privileged_gp_indices \u001b[38;5;241m=\u001b[39m x_test_temp[x_test_temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mindex\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "dp_ori = demographic_parity(x_train, y_train, x_test)\n",
    "print(dp_ori)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
