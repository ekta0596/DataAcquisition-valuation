{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ab2386",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9389daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a17f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('compas-scores-two-years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53938293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['event', 'is_violent_recid', 'is_recid', 'priors_count', 'juv_other_count','juv_misd_count', 'juv_fel_count', 'race', 'age_cat', 'sex','score_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e5c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_compas(df):\n",
    "    df['age_cat'] = df['age_cat'].map({'Less than 25': 0, '25 - 45': 1, 'Greater than 45': 2}).astype(int)    \n",
    "    df['score_text'] = df['score_text'].map({'Low': 0, 'Medium': 1, 'High': 2}).astype(int)    \n",
    "    df['race'] = df['race'].map({'Other': 0, 'African-American': 0, 'Hispanic': 0, 'Native American': 0, 'Asian': 0, 'Caucasian': 1}).astype(int)\n",
    "    df['sex'] = df['sex'].map({'Male': 1, 'Female': 0}).astype(int)    \n",
    "    \n",
    "    df.loc[(df['priors_count'] <= 5), 'priors_count'] = 0\n",
    "    df.loc[(df['priors_count'] > 5) & (df['priors_count'] <= 15), 'priors_count'] = 1\n",
    "    df.loc[(df['priors_count'] > 15), 'priors_count'] = 2\n",
    "    \n",
    "    df.loc[(df['juv_fel_count'] == 0), 'juv_fel_count'] = 0\n",
    "    df.loc[(df['juv_fel_count'] == 1), 'juv_fel_count'] = 1\n",
    "    df.loc[(df['juv_fel_count'] > 1), 'juv_fel_count'] = 2\n",
    "    \n",
    "    df.loc[(df['juv_misd_count'] == 0), 'juv_misd_count'] = 0\n",
    "    df.loc[(df['juv_misd_count'] == 1), 'juv_misd_count'] = 1\n",
    "    df.loc[(df['juv_misd_count'] > 1), 'juv_misd_count'] = 2\n",
    "    \n",
    "    df.loc[(df['juv_other_count'] == 0), 'juv_other_count'] = 0\n",
    "    df.loc[(df['juv_other_count'] == 1), 'juv_other_count'] = 1\n",
    "    df.loc[(df['juv_other_count'] > 1), 'juv_other_count'] = 2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110be361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_compas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23ebc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bdd558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['is_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e9af6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7214\n"
     ]
    }
   ],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d284836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['is_recid', 'is_violent_recid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edd081b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>sex</th>\n",
       "      <th>score_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event  priors_count  juv_other_count  juv_misd_count  juv_fel_count  race  \\\n",
       "0      0             0                0               0              0     0   \n",
       "1      1             0                0               0              0     0   \n",
       "2      0             0                1               0              0     0   \n",
       "3      0             0                0               1              0     0   \n",
       "4      0             0                0               0              0     0   \n",
       "\n",
       "   age_cat  sex  score_text  \n",
       "0        2    1           0  \n",
       "1        1    1           0  \n",
       "2        0    1           0  \n",
       "3        0    1           2  \n",
       "4        1    1           0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd6ac3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column \"event\": [0 1]\n",
      "Unique values in column \"priors_count\": [0 1 2]\n",
      "Unique values in column \"juv_other_count\": [0 1 2]\n",
      "Unique values in column \"juv_misd_count\": [0 1 2]\n",
      "Unique values in column \"juv_fel_count\": [0 2 1]\n",
      "Unique values in column \"race\": [0 1]\n",
      "Unique values in column \"age_cat\": [2 1 0]\n",
      "Unique values in column \"sex\": [1 0]\n",
      "Unique values in column \"score_text\": [0 2 1]\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f'Unique values in column \"{column}\": {unique_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85ce9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_pattern(string1, string2):\n",
    "    if len(string1) == len(string2):\n",
    "        for i in range(len(string1)):\n",
    "            if string1[i].isdigit() and string2[i].isdigit():\n",
    "                if string1[i] != string2[i]:\n",
    "                    return 0\n",
    "        else:\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98d8e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Return the inverted index matrix for the dataset\n",
    "def preprocessing(dataset):\n",
    "    \n",
    "    #Get cardinalities out of the dataset\n",
    "    cardinalities = []\n",
    "#     cardinalities = [[0,1],[0,1],[0,1]]\n",
    "    for col in dataset.columns:\n",
    "        cardinalities.append(dataset[col].unique().tolist())\n",
    "\n",
    "    for cardinality in cardinalities:\n",
    "        cardinality.sort()\n",
    "        \n",
    "    num = 1\n",
    "    for cardinality in cardinalities:\n",
    "        num *= len(cardinality)+1\n",
    "        \n",
    "    print('Total number of patterns in the dataset: ',num)\n",
    "\n",
    "\n",
    "    #Get unique value combinations count\n",
    "    dataset_string = []\n",
    "#     dataset_string = ['010','001','000','011','001']\n",
    "    for i in range(len(dataset)):\n",
    "        dataset_string.append(\"\".join(str(x) for x in dataset.iloc[i].values.tolist()))\n",
    "        \n",
    "    counts = OrderedDict()\n",
    "\n",
    "    for item in dataset_string:\n",
    "        counts[item] = counts.get(item, 0) + 1\n",
    "\n",
    "    data_unique_values = list(counts.keys())\n",
    "    data_value_counts = list(counts.values())\n",
    "    \n",
    "    inverted_ind = []\n",
    "    \n",
    "    #create inverted index matrix\n",
    "    for i,cardinality in enumerate(cardinalities):\n",
    "        for cardinality_val in cardinality:\n",
    "            new_row = []\n",
    "            for val in data_unique_values:\n",
    "                if cardinality_val == int(val[i]):\n",
    "                    new_row.append(1)\n",
    "                else:\n",
    "                    new_row.append(0) \n",
    "            inverted_ind.append(new_row)\n",
    "            \n",
    "    return inverted_ind, data_value_counts, cardinalities\n",
    "        \n",
    "\n",
    "def cov(pattern, dataset):  #tested_OK\n",
    "    \"\"\"\n",
    "    Returns the number of instances in the dataset covered by the given pattern.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        res = match_pattern(pattern, \"\".join(str(x) for x in df.iloc[i].values.tolist()))\n",
    "        if res == 1:\n",
    "            count += 1\n",
    "#     print(count)\n",
    "    return count\n",
    "\n",
    "\n",
    "def coverage_optimized(pattern, inverted_ind, data_value_counts, cardinalities):  #invertedindices  #tested_OK for the example given in the research paper\n",
    "\n",
    "    result_and = [1] * len(inverted_ind[0])\n",
    "    row_index = 0\n",
    "    for i,x in enumerate(pattern):\n",
    "        if x!= 'X':\n",
    "            \n",
    "            #find the value x in cardinalities[i]\n",
    "            index = cardinalities[i].index(int(x))\n",
    "            row_index += index\n",
    "            inverted_ind_row = inverted_ind[row_index]\n",
    "            for j in range(len(inverted_ind_row)):\n",
    "                result_and[j] = int(inverted_ind_row[j] and result_and[j])\n",
    "            row_index -= index\n",
    "            row_index += len(cardinalities[i])\n",
    "        else:\n",
    "            row_index += len(cardinalities[i])      \n",
    "\n",
    "    # DOT Product between the above result and the count array for the datapoints\n",
    "    coverage = sum([x*y for x, y in zip(data_value_counts, result_and)])\n",
    "    return coverage\n",
    "    \n",
    "\n",
    "def generate_parent_nodes(pattern):  #tested_OK\n",
    "    \"\"\"\n",
    "    Generates all parent nodes of the given pattern by replacing one deterministic\n",
    "    cell with a wildcard character.\n",
    "    \"\"\"\n",
    "    parents = []\n",
    "    for i in range(len(pattern)):\n",
    "        new_string = pattern[:i] + \"X\" + pattern[i+1:]\n",
    "        if new_string != pattern:\n",
    "            parents.append(new_string)\n",
    "    return parents\n",
    "\n",
    "\n",
    "def generate_nodes(pattern, cardinalities): #tested_OK\n",
    "    \"\"\"\n",
    "    Generates all nodes on the given pattern and cardinalities based on Rule 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: Make cardinalities 2D vector, so that it can be traversed to find the children of a pattern\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the index of the right-most deterministic element in the pattern\n",
    "    index = len(pattern) - 1\n",
    "    rm_deter = -1\n",
    "    while index >= 0:\n",
    "        if pattern[index] != 'X':\n",
    "            rm_deter = index\n",
    "            break\n",
    "        index -= 1\n",
    "\n",
    "    candidate_nodes = []\n",
    "    rm_deter += 1\n",
    "    if rm_deter >= 0:\n",
    "        while rm_deter < len(pattern):\n",
    "            index = rm_deter\n",
    "            for value in cardinalities[index]:\n",
    "                candidate_node = pattern\n",
    "                candidate_node = pattern[:index] + str(value) + pattern[index+1:] \n",
    "                candidate_nodes.append(candidate_node)\n",
    "            rm_deter += 1\n",
    "\n",
    "    return candidate_nodes\n",
    "\n",
    "\n",
    "def dominance(pattern, mups):\n",
    "    #iterate through the mups, find if any of the mups is an ancestor for the pattern p return 0\n",
    "    # if pattern p is an ancestor for any of the mups return 1\n",
    "    # else return -1\n",
    "    \n",
    "    for m in mups:\n",
    "        for i,x in enumerate(m):\n",
    "            if m[i] != pattern[i]:\n",
    "                if m[i] == 'X' and pattern[i] != 'X':\n",
    "                    return 0\n",
    "                elif m[i] != 'X' and pattern[i] == 'X':\n",
    "                    return 1\n",
    "    \n",
    "    return -1\n",
    "\n",
    "    \n",
    "def deepdiver(dataset, threshold):\n",
    "    \"\"\"\n",
    "    Finds the maximal uncovered patterns in the dataset.\n",
    "    \"\"\" \n",
    "    inverted_index, unique_value_counts, cardinalities = preprocessing(dataset);\n",
    "\n",
    "    stack = ['XXXXXXXXX']\n",
    "    maximal_uncovered = []\n",
    "    while stack:\n",
    "        pattern = stack.pop()\n",
    "        uncovered_flag = False\n",
    "        if dominance(pattern, maximal_uncovered) == 0:\n",
    "            continue\n",
    "        elif dominance(pattern, maximal_uncovered) == 1:\n",
    "            uncovered_flag = False\n",
    "        else: \n",
    "            count = coverage_optimized(pattern, inverted_index, unique_value_counts, cardinalities)\n",
    "            if count < threshold:\n",
    "                uncovered_flag = True\n",
    "        if uncovered_flag:\n",
    "            stack0 = []\n",
    "            stack0.append(pattern)\n",
    "            while stack0:\n",
    "                pattern0 = stack0.pop()\n",
    "                parent_nodes = generate_parent_nodes(pattern0)\n",
    "                for p in parent_nodes:\n",
    "                    count0 = coverage_optimized(p, inverted_index, unique_value_counts, cardinalities )\n",
    "                    if count0 < threshold:\n",
    "                        stack0.append(p)\n",
    "                        break                   \n",
    "                maximal_uncovered.append(pattern)\n",
    "        else:\n",
    "            stack.extend(generate_nodes(pattern, cardinalities))\n",
    "            \n",
    "    print('MUPs are: ', maximal_uncovered)\n",
    "    return maximal_uncovered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2751162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patterns in the dataset:  110592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7214\n"
     ]
    }
   ],
   "source": [
    "inv, d, cardinalities = preprocessing(df)\n",
    "print(coverage_optimized('XXXXXXXXX',inv,d,cardinalities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e2217f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patterns in the dataset:  110592\n",
      "MUPs are:  ['XXXXX1202']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XXXXX1202']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepdiver(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e00d5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patterns in the dataset:  110592\n",
      "MUPs are:  ['XXXXXXX02', 'XXXXXXX01']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XXXXXXX02', 'XXXXXXX01']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepdiver(df, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4ed80ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patterns in the dataset:  110592\n",
      "MUPs are:  ['XXXXXXX02', 'XXXXXXX01', 'XXXXXXX00']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XXXXXXX02', 'XXXXXXX01', 'XXXXXXX00']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepdiver(df, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81e2b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStringsMatchingWithPattern(pattern, df):\n",
    "    \n",
    "    \n",
    "    #Get unique value combinations count\n",
    "    dataset_string = []\n",
    "    for i in range(len(df)):\n",
    "        dataset_string.append(\"\".join(str(x) for x in df.iloc[i].values.tolist()))\n",
    "        \n",
    "    \n",
    "    strings = []\n",
    "    flag = True\n",
    "    for s in dataset_string:\n",
    "        flag = True\n",
    "        for i,x in enumerate(s):\n",
    "            if x != pattern[i]:\n",
    "                if pattern[i] != 'X':\n",
    "#                     print('string:',s[i])\n",
    "#                     print('string:',pattern[i])\n",
    "                    flag = False\n",
    "                    \n",
    "        if flag:\n",
    "            strings.append(s)\n",
    "            \n",
    "    print(len(strings))       \n",
    "    return strings\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d575f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['000000002',\n",
       " '000010002',\n",
       " '110000102',\n",
       " '100000102',\n",
       " '010001102',\n",
       " '120100102',\n",
       " '000000102',\n",
       " '110001102',\n",
       " '000000102',\n",
       " '000000002',\n",
       " '000000102',\n",
       " '100000002',\n",
       " '100000202',\n",
       " '020000202',\n",
       " '010010002',\n",
       " '111001002',\n",
       " '000001002',\n",
       " '100001002',\n",
       " '000000002',\n",
       " '111001102',\n",
       " '000001202',\n",
       " '100000102',\n",
       " '000000102',\n",
       " '020000202',\n",
       " '000000002',\n",
       " '100001002',\n",
       " '000001102',\n",
       " '000000102',\n",
       " '100001102',\n",
       " '000000002',\n",
       " '010000102',\n",
       " '010000102',\n",
       " '100000102',\n",
       " '110001102',\n",
       " '000000102',\n",
       " '100000102',\n",
       " '100000102',\n",
       " '100000002',\n",
       " '010000102',\n",
       " '110000102',\n",
       " '000001202',\n",
       " '000000002',\n",
       " '001201002',\n",
       " '010000102',\n",
       " '002000002',\n",
       " '100001102',\n",
       " '000001102',\n",
       " '100000002',\n",
       " '110100102',\n",
       " '010001102',\n",
       " '100000102',\n",
       " '000001002',\n",
       " '100000202',\n",
       " '010000202',\n",
       " '100001102',\n",
       " '112000102',\n",
       " '100010002',\n",
       " '000000002',\n",
       " '012200102',\n",
       " '010000202',\n",
       " '010000102',\n",
       " '001200002',\n",
       " '100000002',\n",
       " '100000102',\n",
       " '100000102',\n",
       " '100000102',\n",
       " '100000002',\n",
       " '120000102',\n",
       " '110000102',\n",
       " '010001202',\n",
       " '100000102',\n",
       " '000001102',\n",
       " '100010002',\n",
       " '010000202',\n",
       " '000001102',\n",
       " '010010202',\n",
       " '000000002',\n",
       " '000100002',\n",
       " '112200102',\n",
       " '000001002',\n",
       " '001001002',\n",
       " '000001102',\n",
       " '000000102',\n",
       " '010200102',\n",
       " '100001102',\n",
       " '010000102',\n",
       " '000001102',\n",
       " '100000002',\n",
       " '000000002',\n",
       " '000000102',\n",
       " '100000002',\n",
       " '100000002',\n",
       " '000000002',\n",
       " '100100002',\n",
       " '120200102',\n",
       " '111200002',\n",
       " '100001102',\n",
       " '111001002',\n",
       " '110000102',\n",
       " '100000002',\n",
       " '000001002',\n",
       " '000000102',\n",
       " '000000102',\n",
       " '000000102',\n",
       " '000100002',\n",
       " '120001102',\n",
       " '000000002',\n",
       " '000000002',\n",
       " '010001102',\n",
       " '000001102',\n",
       " '000001002',\n",
       " '121100202',\n",
       " '000001002',\n",
       " '010001102',\n",
       " '110000102',\n",
       " '000001102',\n",
       " '010020102',\n",
       " '100001002',\n",
       " '100000002',\n",
       " '000000002',\n",
       " '100000102',\n",
       " '100000002',\n",
       " '000000102',\n",
       " '010000102',\n",
       " '111000002',\n",
       " '000000102',\n",
       " '110001002',\n",
       " '020001102',\n",
       " '011000102',\n",
       " '110000202',\n",
       " '000001202',\n",
       " '120001202',\n",
       " '000000102',\n",
       " '100000002',\n",
       " '000000002',\n",
       " '110001102',\n",
       " '100001202',\n",
       " '000000102',\n",
       " '110000102',\n",
       " '100001002',\n",
       " '100000002',\n",
       " '012001102',\n",
       " '110100102',\n",
       " '010001102',\n",
       " '110000102',\n",
       " '101001102',\n",
       " '100001102',\n",
       " '110001102',\n",
       " '110000202',\n",
       " '000000102',\n",
       " '100000002',\n",
       " '000000102',\n",
       " '100000102',\n",
       " '000000102',\n",
       " '000001202',\n",
       " '100001002',\n",
       " '020001202',\n",
       " '000000102',\n",
       " '110000102',\n",
       " '000001102',\n",
       " '010000102',\n",
       " '000001002',\n",
       " '120000102',\n",
       " '100001002',\n",
       " '100000002',\n",
       " '010000002',\n",
       " '110000102',\n",
       " '000000002',\n",
       " '100000102',\n",
       " '010001102',\n",
       " '010000102',\n",
       " '000100002',\n",
       " '110100102',\n",
       " '120000202',\n",
       " '100000102',\n",
       " '000000102',\n",
       " '100001002',\n",
       " '000000102',\n",
       " '000001102',\n",
       " '120020102',\n",
       " '000000002',\n",
       " '000001002',\n",
       " '100001102',\n",
       " '110000102',\n",
       " '001001002',\n",
       " '100001102',\n",
       " '000000102',\n",
       " '000001102',\n",
       " '100000102',\n",
       " '110000102']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getStringsMatchingWithPattern('XXXXXXX02', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5ac9bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['000001000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '100000000',\n",
       " '000001000',\n",
       " '100000000',\n",
       " '000010000',\n",
       " '000000000',\n",
       " '000001000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000001000',\n",
       " '000000000',\n",
       " '001001000',\n",
       " '000000000',\n",
       " '100000000',\n",
       " '101000000',\n",
       " '000000000',\n",
       " '000001000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '100001000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000001000',\n",
       " '100001000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '100000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000001000',\n",
       " '100000000',\n",
       " '000001000',\n",
       " '000001000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '100000000',\n",
       " '000000000',\n",
       " '000001000',\n",
       " '000000000',\n",
       " '000100000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '100000000',\n",
       " '000000000',\n",
       " '100000000',\n",
       " '000000000',\n",
       " '000001000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '002001000',\n",
       " '100000000',\n",
       " '100000000',\n",
       " '000001000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '101000000',\n",
       " '000001000',\n",
       " '000000000',\n",
       " '002001000',\n",
       " '000000000',\n",
       " '100000000',\n",
       " '100000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '100000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '000000000',\n",
       " '100000000',\n",
       " '100000000',\n",
       " '000000000',\n",
       " '000001000',\n",
       " '000000000']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getStringsMatchingWithPattern('XXXXXX000', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a880744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
