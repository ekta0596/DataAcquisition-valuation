{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b63151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1749a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['status', 'duration', 'credit_hist', 'purpose', 'credit_amt', 'savings', 'employment', 'installment_rate', 'personal_status', 'debtors', 'residencesince', 'property', 'age', 'install_plans', 'housing', 'existing_credits', 'job', 'maintenance_paying_people', 'telephone', 'foreign_worker', 'result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9825a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('german.data', names=cols, sep=\" \", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf307cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_hist</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amt</th>\n",
       "      <th>savings</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>debtors</th>\n",
       "      <th>...</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>install_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>maintenance_paying_people</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>67</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>22</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>49</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>45</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>53</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  status  duration credit_hist purpose  credit_amt savings employment  \\\n",
       "0    A11         6         A34     A43        1169     A65        A75   \n",
       "1    A12        48         A32     A43        5951     A61        A73   \n",
       "2    A14        12         A34     A46        2096     A61        A74   \n",
       "3    A11        42         A32     A42        7882     A61        A74   \n",
       "4    A11        24         A33     A40        4870     A61        A73   \n",
       "\n",
       "   installment_rate personal_status debtors  ...  property age  install_plans  \\\n",
       "0                 4             A93    A101  ...      A121  67           A143   \n",
       "1                 2             A92    A101  ...      A121  22           A143   \n",
       "2                 2             A93    A101  ...      A121  49           A143   \n",
       "3                 2             A93    A103  ...      A122  45           A143   \n",
       "4                 3             A93    A101  ...      A124  53           A143   \n",
       "\n",
       "  housing existing_credits   job maintenance_paying_people  telephone  \\\n",
       "0    A152                2  A173                         1       A192   \n",
       "1    A152                1  A173                         1       A191   \n",
       "2    A152                1  A172                         2       A191   \n",
       "3    A153                1  A173                         2       A191   \n",
       "4    A153                2  A173                         2       A191   \n",
       "\n",
       "  foreign_worker result  \n",
       "0           A201      1  \n",
       "1           A201      2  \n",
       "2           A201      1  \n",
       "3           A201      1  \n",
       "4           A201      2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fd66959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_german(df): \n",
    "    df['status'] = df['status'].map({'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}).astype(int)\n",
    "    df['credit_hist'] = df['credit_hist'].map({'A34': 0, 'A33': 1, 'A32': 2, 'A31': 3, 'A30': 4}).astype(int)\n",
    "    df.loc[(df['credit_amt'] <= 2000), 'credit_amt'] = 0\n",
    "    df.loc[(df['credit_amt'] > 2000) & (df['credit_amt'] <= 5000), 'credit_amt'] = 1\n",
    "    df.loc[(df['credit_amt'] > 5000), 'credit_amt'] = 2   \n",
    "    df.loc[(df['duration'] <= 12), 'duration'] = 0\n",
    "    df.loc[(df['duration'] > 12) & (df['duration'] <= 24), 'duration'] = 1\n",
    "    df.loc[(df['duration'] > 24) & (df['duration'] <= 36), 'duration'] = 2\n",
    "    df.loc[(df['duration'] > 36), 'duration'] = 3\n",
    "    df['age'] = df['age'].apply(lambda x : 1 if x >= 45 else 0) # 1 if old, 0 if young\n",
    "    df['savings'] = df['savings'].map({'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}).astype(int)\n",
    "    df['employment'] = df['employment'].map({'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}).astype(int)    \n",
    "    df['gender'] = df['personal_status'].map({'A91': 1, 'A92': 0, 'A93': 1, 'A94': 1, 'A95': 0}).astype(int)\n",
    "    df['debtors'] = df['debtors'].map({'A101': 0, 'A102': 1, 'A103': 2}).astype(int)\n",
    "    df['property'] = df['property'].map({'A121': 3, 'A122': 2, 'A123': 1, 'A124': 0}).astype(int)        \n",
    "    df['install_plans'] = df['install_plans'].map({'A141': 1, 'A142': 1, 'A143': 0}).astype(int)\n",
    "    df['job'] = df['job'].map({'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}).astype(int)    \n",
    "    df['telephone'] = df['telephone'].map({'A191': 0, 'A192': 1}).astype(int)\n",
    "    df['foreign_worker'] = df['foreign_worker'].map({'A201': 1, 'A202': 0}).astype(int)\n",
    "    pd.get_dummies(df, columns=['purpose', 'housing'], drop_first=True)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b75816",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_german(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a20a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"purpose\", \"housing\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "629631e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"personal_status\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4f8c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an empty array for the results\n",
    "# pp_array = np.array([])\n",
    "\n",
    "# # Push values to the array\n",
    "# pp_array = np.append(my_array, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a361162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['status', 'duration', 'credit_hist', 'credit_amt', 'savings',\n",
       "       'employment', 'installment_rate', 'debtors', 'residencesince',\n",
       "       'property', 'age', 'install_plans', 'existing_credits', 'job',\n",
       "       'maintenance_paying_people', 'telephone', 'foreign_worker', 'result',\n",
       "       'gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50d0aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['status', 'duration', 'credit_hist', 'credit_amt', 'savings',\n",
    "       'employment', 'installment_rate', 'debtors', 'residencesince',\n",
    "       'property', 'age', 'install_plans', 'existing_credits', 'job',\n",
    "       'maintenance_paying_people', 'telephone', 'foreign_worker',\n",
    "       'gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222b65d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"result\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af0c38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c58fd9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_random_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89f44db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_parity(x_train, y_train):\n",
    "    # find the predictive probabilities for the sensitive and non-sensitive groups \n",
    "\n",
    "    logistic_model = LogisticRegression(max_iter=1000)\n",
    "    logistic_model.fit(x_train, y_train.values.ravel())\n",
    "    y_pred = logistic_model.predict(x_test)\n",
    "    y_pred_prob = logistic_model.predict_proba(x_test)\n",
    "    accuracy_score(y_test, y_pred)\n",
    "    groups_age =  df.groupby(df['age'])\n",
    "    protected_group_age_df = groups_age.get_group(1)\n",
    "    non_protected_group_age_df = groups_age.get_group(0)\n",
    "    y_pred = logistic_model.predict(x_test)\n",
    "\n",
    "    # There are various fairness metrics defined in the 'Fairness Definitions Explained' paper based on the predicted probabilities and actual outcome\n",
    "\n",
    "    # 1. Test fairness -> P(Y=1|S=s, G=m) = P(Y=1|S=s, G=f), which can be used for age(protected and non-protected classes)\n",
    "    # 2. Well-calibration -> P(Y=1|S=s, G=m) = P(Y=1|S=s, G=f) = s, which can be used for age(protected and non-protected classes)\n",
    "    # 3. Balance for positive class -> E(S|Y=1,G=m) = E(S|Y=1,G=f), which can be used for age(protected and non-protected classes)\n",
    "    # 4. Balance for negative class -> E(S|Y=0,G=m) = E(S|Y=0,G=f), which can be used for age(protected and non-protected classes)\n",
    "\n",
    "    # Now, we need to find the P(Å· = 1 | y = 1, G = 0) and P(Å· = 1 | y = 1, G = 1) as G is the sensitive attribute here\n",
    "    # Find the average y_pred_proba where the actual outcome Y = 1 for the divided groups \n",
    "\n",
    "    non_protected_group_age_credresult_1_df = non_protected_group_age_df.groupby(non_protected_group_age_df['result']).get_group(1)\n",
    "\n",
    "    #Drop the result column as the logistic regression model will accept 18 columns as input.\n",
    "    non_protected_group_age_credresult_1_df = non_protected_group_age_credresult_1_df.drop([\"result\"], axis=1)\n",
    "\n",
    "    # Need to find the predictive probability for the dataframe and then finally find the average\n",
    "    y_pred_non_protected_group_age_credresult_1 = logistic_model.predict(non_protected_group_age_credresult_1_df)\n",
    "\n",
    "    protected_group_age_credresult_1_df = protected_group_age_df.groupby(protected_group_age_df['result']).get_group(1)\n",
    "\n",
    "    #Drop the result column as the logistic regression model will accept 18 columns as input.\n",
    "    protected_group_age_credresult_1_df = protected_group_age_credresult_1_df.drop([\"result\"], axis=1)\n",
    "\n",
    "    # Need to find the predict probability for the dataframe and then finally find the average\n",
    "    y_pred_protected_group_age_credresult_1 = logistic_model.predict(protected_group_age_credresult_1_df)\n",
    "\n",
    "    # Need to find the predict probability for the dataframe and then finally find the average\n",
    "    y_pred_protected_group_age_credresult_1 = logistic_model.predict_proba(protected_group_age_credresult_1_df)\n",
    "    y_pred_non_protected_group_age_credresult_1 = logistic_model.predict_proba(non_protected_group_age_credresult_1_df)\n",
    "    \n",
    "    protected_pp = y_pred_protected_group_age_credresult_1.transpose()[0].mean()\n",
    "    non_protected_pp = y_pred_non_protected_group_age_credresult_1.transpose()[0].mean()\n",
    "\n",
    "    return protected_pp, non_protected_pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37353cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random data acquisition - Guassian distribution \n",
    "\n",
    "def data_acquisition_guassian(x_train, y_train):\n",
    "    for num_points in range(100, 1001, 100):\n",
    "        random_data = pd.DataFrame()\n",
    "        random_tuples = x.sample(n=num_points, random_state=40)\n",
    "\n",
    "        for column in x.columns:\n",
    "            mean = x[column].mean()\n",
    "            std_dev = x[column].std()\n",
    "            random_values = np.random.normal(mean, std_dev, num_points)\n",
    "\n",
    "            random_values = np.clip(random_values, 0, None)\n",
    "            random_values = np.round(random_values).astype(int)\n",
    "\n",
    "            random_data[column] = random_values\n",
    "\n",
    "        # random_data is x_rand and we need to find out the labels for them using KNN\n",
    "\n",
    "        k = 3  # The number of neighbors to consider\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(x_train, y_train)\n",
    "\n",
    "        y_rand = knn.predict(random_data)\n",
    "        column_names = ['result']\n",
    "        y_rand = pd.DataFrame(y_rand, columns=column_names)\n",
    "        \n",
    "        # y_rand = y_rand.ravel()\n",
    "\n",
    "        x_train = pd.concat([x_train, random_data])\n",
    "        y_train = pd.concat([y_train, y_rand])\n",
    "\n",
    "        pp_protected_gp, pp_nonprotectedgp_gp, diff = predictive_parity(x_train, y_train)\n",
    "        print('PP for ', num_points ,' datapoints acquired is: ', pp_protected_gp, pp_nonprotectedgp_gp, pp_protected_gp - pp_nonprotectedgp_gp )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20bd8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random data acquisition from the dataset \n",
    "\n",
    "def data_acquisition_frm_dataset(x_train, y_train):\n",
    "    \n",
    "    pp_protected_gp, pp_nonprotectedgp_gp = predictive_parity(x_train, y_train)\n",
    "    print('PP for    0  datapoints acquired is: ', pp_protected_gp, pp_nonprotectedgp_gp)\n",
    "\n",
    "    for num_points in range(100, 1001, 100):\n",
    "        \n",
    "        filtered_df = df[df['gender'] == 0]\n",
    "        random_tuples = filtered_df.iloc[np.random.choice(len(filtered_df), size=num_points, replace=True)] \n",
    "        \n",
    "        # print(random_tuples.head())\n",
    "        \n",
    "        #random_tuples = df.sample(n=num_points, weights=fixed_attributes, replace = True, random_state=30)\n",
    "       # random_tuples = df.sample(n=num_points)\n",
    "\n",
    "        x_rand = random_tuples[['status', 'duration', 'credit_hist', 'credit_amt', 'savings',\n",
    "           'employment', 'installment_rate', 'debtors', 'residencesince',\n",
    "           'property', 'age', 'install_plans', 'existing_credits', 'job',\n",
    "           'maintenance_paying_people', 'telephone', 'foreign_worker',\n",
    "           'gender']]\n",
    "\n",
    "        y_rand = random_tuples[['result']]\n",
    "\n",
    "        x_train_df = pd.concat([x_train, x_rand])\n",
    "        y_train_df = pd.concat([y_train, y_rand])\n",
    "\n",
    "\n",
    "        pp_protected_gp, pp_nonprotectedgp_gp = predictive_parity(x_train_df, y_train_df)\n",
    "        print('PP for ', num_points ,' datapoints acquired is: ', pp_protected_gp, pp_nonprotectedgp_gp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "685d0e0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP for    0  datapoints acquired is:  0.8061534338247007 0.7585539060046168\n",
      "PP for  100  datapoints acquired is:  0.8177016846140222 0.7520159429539339\n",
      "PP for  200  datapoints acquired is:  0.8126402813435551 0.7467108963863104\n",
      "PP for  300  datapoints acquired is:  0.8189115935308166 0.7589706167882023\n",
      "PP for  400  datapoints acquired is:  0.8111985157300712 0.7535585991866746\n",
      "PP for  500  datapoints acquired is:  0.8448753425149694 0.7428950178206577\n",
      "PP for  600  datapoints acquired is:  0.8328854393700754 0.7466418667633722\n",
      "PP for  700  datapoints acquired is:  0.8325899476632885 0.7540120955562323\n",
      "PP for  800  datapoints acquired is:  0.8396698847981866 0.7517220428015805\n",
      "PP for  900  datapoints acquired is:  0.8797027319957509 0.7397703227444231\n",
      "PP for  1000  datapoints acquired is:  0.8556347899166442 0.7514910990562952\n"
     ]
    }
   ],
   "source": [
    "data_acquisition_frm_dataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589a3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5607d480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
